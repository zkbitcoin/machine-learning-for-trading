{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to generate long-short trading signals with a Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:39:31.003564Z",
     "start_time": "2021-04-16T00:39:30.997727Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:39:32.555782Z",
     "start_time": "2021-04-16T00:39:31.361405Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "from io import StringIO\n",
    "import sys, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:39:32.560522Z",
     "start_time": "2021-04-16T00:39:32.557203Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the path to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.insert(0, parent_dir)\n",
    "from utils import MultipleTimeSeriesCV, format_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:39:32.601570Z",
     "start_time": "2021-04-16T00:39:32.562218Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:39:32.610068Z",
     "start_time": "2021-04-16T00:39:32.602934Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:39:32.620245Z",
     "start_time": "2021-04-16T00:39:32.611341Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YEAR = 252\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:39:32.869505Z",
     "start_time": "2021-04-16T00:39:32.864763Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:39:33.377362Z",
     "start_time": "2021-04-16T00:39:33.375100Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('results', 'return_predictions')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the notebook [japanese_equity_features](03_japanese_equity_features.ipynb) in this directory for data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:41:53.097614Z",
     "start_time": "2021-04-16T00:41:52.126778Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data.h5', 'stooq/japan/equities')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with 941 tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:41:54.425801Z",
     "start_time": "2021-04-16T00:41:54.400986Z"
    }
   },
   "outputs": [],
   "source": [
    "len(data.index.unique('ticker'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select universe of 250 most-liquid stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rank the stocks by their daily average dollar volume and select those with the 250 lowest average ranks and thus highest average volumes for the 2010-2017 period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:02:50.607742Z",
     "start_time": "2021-02-23T21:02:42.227048Z"
    }
   },
   "outputs": [],
   "source": [
    "prices = (pd.read_hdf(DATA_DIR / 'assets.h5', 'stooq/jp/tse/stocks/prices')\n",
    "          .loc[idx[:, '2010': '2017'], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:02:52.631450Z",
     "start_time": "2021-02-23T21:02:50.608766Z"
    }
   },
   "outputs": [],
   "source": [
    "dollar_vol = prices.close.mul(prices.volume)\n",
    "dollar_vol_rank = dollar_vol.groupby(level='date').rank(ascending=False)\n",
    "universe = dollar_vol_rank.groupby(level='ticker').mean().nsmallest(250).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultipleTimeSeriesCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Chapter 7 - Linear Models](../07_linear_models) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:02:52.637665Z",
     "start_time": "2021-02-23T21:02:52.632697Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = MultipleTimeSeriesCV(n_splits=36,\n",
    "                          test_period_length=21,\n",
    "                          lookahead=5,\n",
    "                          train_period_length=2 * 252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each fold, the train and test periods are separated by a `lookahead` number of periods and thus do not overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:02:57.362939Z",
     "start_time": "2021-02-23T21:02:52.638837Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, (train_idx, test_idx) in enumerate(cv.split(X=data)):\n",
    "    train = data.iloc[train_idx]\n",
    "    train_dates = train.index.get_level_values('date')\n",
    "    test = data.iloc[test_idx]\n",
    "    test_dates = test.index.get_level_values('date')\n",
    "    df = pd.concat([train.reset_index(), test.reset_index()])\n",
    "    n = len(df)\n",
    "    assert n == len(df.drop_duplicates())\n",
    "    msg = f'Training: {train_dates.min().date()}-{train_dates.max().date()} '\n",
    "    msg += f'({train.groupby(level=\"ticker\").size().value_counts().index[0]:,.0f} days) | '\n",
    "    msg += f'Test: {test_dates.min().date()}-{test_dates.max().date()} '\n",
    "    msg += f'({test.groupby(level=\"ticker\").size().value_counts().index[0]:,.0f} days)'\n",
    "    print(msg)\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Time Period and Horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model selection step, we restrict training and validation sets to the 2010-2017 period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:03:05.380614Z",
     "start_time": "2021-02-23T21:03:02.618027Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.sort_index()\n",
    "\n",
    "# Initialize an empty DataFrame to accumulate results\n",
    "cv_data_combined = pd.DataFrame()\n",
    "\n",
    "# List to store errors encountered\n",
    "errors = []\n",
    "\n",
    "for item in universe:\n",
    "    try:\n",
    "        # Attempt to access the data for the current item\n",
    "        cv_data = data.loc[idx[item, :'2017'], :]\n",
    "        \n",
    "        # Append the data to the combined DataFrame\n",
    "        cv_data_combined = pd.concat([cv_data_combined, cv_data])\n",
    "        \n",
    "    except KeyError as e:\n",
    "        pass\n",
    "        # Handle the KeyError (e.g., log it, skip the item, etc.)\n",
    "        #print(f\"KeyError for item '{item}': {e}\")\n",
    "\n",
    "# Assuming that `data` has a MultiIndex and you want `cv_data_combined` to have a similar structure\n",
    "# Check if `data` has a MultiIndex and if so, get the index names\n",
    "if isinstance(data.index, pd.MultiIndex):\n",
    "    index_names = data.index.names\n",
    "    if index_names:  # Ensure there are index names to use\n",
    "        # Reconstruct MultiIndex based on the current index levels in `cv_data_combined`\n",
    "        # Here we assume that `cv_data_combined` index levels are correctly aligned but named differently\n",
    "        # Let's just use the index from the original data if needed\n",
    "        cv_data_combined.index = pd.MultiIndex.from_tuples(cv_data_combined.index, names=index_names)\n",
    "\n",
    "# Extract unique tickers\n",
    "if isinstance(cv_data_combined.index, pd.MultiIndex):\n",
    "    tickers = cv_data_combined.index.get_level_values('ticker').unique()\n",
    "else:\n",
    "    # Handle case where index is not MultiIndex\n",
    "    tickers = cv_data_combined.index.unique()\n",
    "\n",
    "# Assign cv_data_combined to cv_data\n",
    "cv_data = cv_data_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist the data to save some time when running another experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:03:05.443610Z",
     "start_time": "2021-02-23T21:03:05.381787Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_data.to_hdf('data.h5', 'stooq/japan/equities/cv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:03:05.458303Z",
     "start_time": "2021-02-23T21:03:05.444904Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('data.h5') as store:\n",
    "    print(store.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're picking prediction horizons of 1, 5, 10 and 21 days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:03:07.317733Z",
     "start_time": "2021-02-23T21:03:07.315943Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lookaheads = [1, 5, 10, 21]\n",
    "lookaheads = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's quick to run and quite informative, we generate linear regression baseline predictions. See [Chapter 7 - Linear Models](../07_linear_models) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:03:10.361623Z",
     "start_time": "2021-02-23T21:03:10.359925Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:03:10.484894Z",
     "start_time": "2021-02-23T21:03:10.479559Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(cv_data.filter(like='fwd').columns)\n",
    "features = cv_data.columns.difference(labels).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set five different training lengths from 3 months to 5 years, and two test periods as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:03:13.489653Z",
     "start_time": "2021-02-23T21:03:13.487857Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_lengths = [5 * YEAR, 3 * YEAR, YEAR, 126, 63]\n",
    "#test_lengths = [5, 21]\n",
    "train_lengths = [1]\n",
    "test_lengths = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since linear regression has no hyperparameters, our CV parameters are the cartesian product of prediction horizon and train/test period lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:03:13.862028Z",
     "start_time": "2021-02-23T21:03:13.860080Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterate over these parameters and train/validate the linear regression model while capturing the information coefficient of the model predictions, measure both on a daily basis and for each complete fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:13.550374Z",
     "start_time": "2021-02-23T21:03:14.743079Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_metrics = []\n",
    "for lookahead, train_length, test_length in tqdm(test_params):\n",
    "    label = f'fwd_ret_{lookahead:02}'\n",
    "    df = cv_data.loc[:, features + [label]].dropna()\n",
    "    X, y = df.drop(label, axis=1), df[label]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    ic, preds = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=X)):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        preds.append(y_test.to_frame('y_true').assign(y_pred=y_pred))\n",
    "        ic.append(spearmanr(y_test, y_pred)[0])\n",
    "    preds = pd.concat(preds)\n",
    "    lr_metrics.append([\n",
    "        lookahead, train_length, test_length,\n",
    "        np.mean(ic),\n",
    "        spearmanr(preds.y_true, preds.y_pred)[0]\n",
    "    ])\n",
    "\n",
    "columns = ['lookahead', 'train_length', 'test_length', 'ic_by_day', 'ic']\n",
    "lr_metrics = pd.DataFrame(lr_metrics, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:13.559369Z",
     "start_time": "2021-02-23T21:06:13.551735Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_metrics.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Coefficient distribution by Lookahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data to long `seaborn`-friendly format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:13.581232Z",
     "start_time": "2021-02-23T21:06:13.560493Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_metrics_long = pd.concat([(lr_metrics.drop('ic', axis=1)\n",
    "                              .rename(columns={'ic_by_day': 'ic'})\n",
    "                              .assign(Measured='By Day')),\n",
    "                             lr_metrics.drop('ic_by_day', axis=1)\n",
    "                             .assign(Measured='Overall')])\n",
    "lr_metrics_long.columns=['Lookahead', 'Train Length', 'Test Length', 'IC', 'Measure']\n",
    "lr_metrics_long.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot both IC measures for the various CV parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:14.939908Z",
     "start_time": "2021-02-23T21:06:13.694370Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Train Length',\n",
    "            y='IC',\n",
    "            hue='Test Length',\n",
    "            col='Lookahead',\n",
    "            row='Measure',\n",
    "            data=lr_metrics_long,\n",
    "            kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the distributions of each IC metric for the different prediction horizons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:21.531611Z",
     "start_time": "2021-02-23T21:06:21.262501Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes =plt.subplots(ncols=2, figsize=(14,5), sharey=True)\n",
    "sns.boxplot(x='lookahead', y='ic_by_day',data=lr_metrics, ax=axes[0])\n",
    "axes[0].set_title('IC by Day')\n",
    "sns.boxplot(x='lookahead', y='ic',data=lr_metrics, ax=axes[1])\n",
    "axes[1].set_title('IC Overall')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "axes[1].set_ylabel('')\n",
    "sns.despine()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the best train/test period settings for the four prediction horizons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:38.980665Z",
     "start_time": "2021-02-23T21:06:38.968811Z"
    }
   },
   "outputs": [],
   "source": [
    "(lr_metrics.groupby('lookahead', group_keys=False)\n",
    " .apply(lambda x: x.nlargest(3, 'ic')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:39.692899Z",
     "start_time": "2021-02-23T21:06:39.687816Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_metrics.to_csv(results_path / 'lin_reg_performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Random Forest Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to obtain the LightGBM feature importance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:42.973574Z",
     "start_time": "2021-02-23T21:06:42.971491Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fi(model):\n",
    "    fi = model.feature_importance(importance_type='gain')\n",
    "    return (pd.Series(fi / fi.sum(),\n",
    "                      index=model.feature_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM base parameter settings that are independent of hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:43.275439Z",
     "start_time": "2021-02-23T21:06:43.273605Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_params = dict(boosting_type='rf',\n",
    "                   objective='regression',\n",
    "                   bagging_freq=1,\n",
    "                   verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run this experiment with different parameters for the bagging and feature fractions that determine the degree of randomization as well as the minimum number of samples for a split to control overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:43.723643Z",
     "start_time": "2021-02-23T21:06:43.721635Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bagging_fraction_opts = [.5, .75, .95]\n",
    "feature_fraction_opts = [.75, .95]\n",
    "min_data_in_leaf_opts = [250, 500, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us 3x2x3=18 parameter combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:44.011435Z",
     "start_time": "2021-02-23T21:06:44.008386Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_params = list(product(bagging_fraction_opts,\n",
    "                         feature_fraction_opts,\n",
    "                         min_data_in_leaf_opts))\n",
    "n_cv_params = len(cv_params)\n",
    "n_cv_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To limit the running time, we can randomly sample a subset of the parameter combinations (here: 50%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:47.930930Z",
     "start_time": "2021-02-23T21:06:47.927983Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_proportion = .5\n",
    "sample_size = int(sample_proportion * n_cv_params)\n",
    "\n",
    "cv_param_sample = np.random.choice(list(range(n_cv_params)), \n",
    "                                     size=int(sample_size), \n",
    "                                     replace=False)\n",
    "cv_params_ = [cv_params[i] for i in cv_param_sample]\n",
    "print('# CV parameters:', len(cv_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tune the number of trees by evaluating a fully grown forest for various smaller sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:55.150158Z",
     "start_time": "2021-02-23T21:06:55.148138Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_iterations = [25] + list(range(50, 501, 25))\n",
    "num_boost_round = num_iterations[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Period Lenghts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above for linear regression, we define a range of train/test period length:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:58.294789Z",
     "start_time": "2021-02-23T21:06:58.292755Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_lengths = [5 * YEAR, 3 * YEAR, YEAR, 126, 63]\n",
    "#test_lengths = [5, 21]\n",
    "train_lengths = [1]\n",
    "test_lengths = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:06:58.593988Z",
     "start_time": "2021-02-23T21:06:58.592185Z"
    }
   },
   "outputs": [],
   "source": [
    "test_params = list(product(train_lengths, test_lengths))\n",
    "n_test_params = len(test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as for the model parameters, we can randomly sample from the 5 x 2 = 8 training configurations (here: 50%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:07:03.099343Z",
     "start_time": "2021-02-23T21:07:03.096099Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_proportion = 1.0\n",
    "sample_size = int(sample_proportion * n_test_params)\n",
    "\n",
    "test_param_sample = np.random.choice(list(range(n_test_params)), \n",
    "                                     size=int(sample_size), \n",
    "                                     replace=False)\n",
    "test_params_ = [test_params[i] for i in test_param_sample]\n",
    "print('Train configs:', len(test_params_))\n",
    "print('CV Iterations:', len(cv_params_) * len(test_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To leverage LightGBM's ability to handle categorical variables, we need to define them; we'll also `factorize` them so they are both integer-encoded and start at zero (optional, but otherwise throws a warning) as expected by LightGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:07:13.475533Z",
     "start_time": "2021-02-23T21:07:13.416092Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categoricals = ['year', 'weekday', 'month']\n",
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up some helper variabels and storage locations to faciliate the CV process and result storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:07:19.937133Z",
     "start_time": "2021-02-23T21:07:19.932175Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = sorted(cv_data.filter(like='fwd').columns)\n",
    "features = cv_data.columns.difference(labels).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:07:20.139982Z",
     "start_time": "2021-02-23T21:07:20.138149Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:07:20.359622Z",
     "start_time": "2021-02-23T21:07:20.357958Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_store = Path(results_path / 'parameter_tuning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:07:20.542696Z",
     "start_time": "2021-02-23T21:07:20.540238Z"
    }
   },
   "outputs": [],
   "source": [
    "ic_cols = ['bagging_fraction',\n",
    "           'feature_fraction',\n",
    "           'min_data_in_leaf',\n",
    "           't'] + [str(n) for n in num_iterations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the following steps:\n",
    "- we iterate over the prediction horizons and train/test period length, \n",
    "- set up the `MultipleTimeSeriesCV` accordingly\n",
    "- create the binary LightGBM dataset with the appropriate target, and\n",
    "- iterate over the model hyperparamters to train and validate the model while capturing the relevant performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T13:37:54.346461Z",
     "start_time": "2020-06-20T04:04:55.813656Z"
    }
   },
   "outputs": [],
   "source": [
    "for lookahead in lookaheads:\n",
    "    for train_length, test_length in test_params_:\n",
    "        n_splits = int(2 * YEAR / test_length)\n",
    "        print(f'Lookahead: {lookahead:2.0f} | Train: {train_length:3.0f} | '\n",
    "              f'Test: {test_length:2.0f} | Params: {len(cv_params_):3.0f}')\n",
    "\n",
    "        cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                                  test_period_length=test_length,\n",
    "                                  train_period_length=train_length,\n",
    "                                  lookahead=lookahead)\n",
    "\n",
    "        label = label_dict[lookahead]\n",
    "        outcome_data = data.loc[:, features + [label]].dropna()\n",
    "\n",
    "        lgb_data = lgb.Dataset(data=outcome_data.drop(label, axis=1),\n",
    "                               label=outcome_data[label],\n",
    "                               categorical_feature=categoricals,\n",
    "                               free_raw_data=False)\n",
    "        predictions, daily_ic, ic, feature_importance = [], [], [], []\n",
    "        key = f'{lookahead}/{train_length}/{test_length}'\n",
    "        T = 0\n",
    "        for p, (bagging_fraction, feature_fraction, min_data_in_leaf) in enumerate(cv_params_):\n",
    "            params = base_params.copy()\n",
    "            params.update(dict(bagging_fraction=bagging_fraction,\n",
    "                               feature_fraction=feature_fraction,\n",
    "                               min_data_in_leaf=min_data_in_leaf))\n",
    "\n",
    "            start = time()\n",
    "            cv_preds, nrounds = [], []\n",
    "            for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "                lgb_train = lgb_data.subset(used_indices=train_idx.tolist(), params=params).construct()\n",
    "                lgb_test = lgb_data.subset(used_indices=test_idx.tolist(), params=params).construct()\n",
    "\n",
    "                model = lgb.train(params=params,\n",
    "                                  train_set=lgb_train,\n",
    "                                  num_boost_round=num_boost_round)\n",
    "                if i == 0:\n",
    "                    fi = get_fi(model).to_frame()\n",
    "                else:\n",
    "                    fi[i] = get_fi(model)\n",
    "\n",
    "                test_set = outcome_data.iloc[test_idx, :]\n",
    "                X_test = test_set.loc[:, model.feature_name()]\n",
    "                y_test = test_set.loc[:, label]\n",
    "                y_pred = {str(n): model.predict(X_test, num_iteration=n)\n",
    "                          for n in num_iterations}\n",
    "                cv_preds.append(y_test.to_frame(\n",
    "                    'y_test').assign(**y_pred).assign(i=i))\n",
    "                nrounds.append(model.best_iteration)\n",
    "            feature_importance.append(fi.T.describe().T.assign(bagging_fraction=bagging_fraction,\n",
    "                                                               feature_fraction=feature_fraction,\n",
    "                                                               min_data_in_leaf=min_data_in_leaf))\n",
    "            cv_preds = pd.concat(cv_preds).assign(bagging_fraction=bagging_fraction,\n",
    "                                                  feature_fraction=feature_fraction,\n",
    "                                                  min_data_in_leaf=min_data_in_leaf)\n",
    "\n",
    "            predictions.append(cv_preds)\n",
    "            by_day = cv_preds.groupby(level='date')\n",
    "            ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test,\n",
    "                                                                    x[str(n)])[0]).to_frame(n)\n",
    "                                   for n in num_iterations], axis=1)\n",
    "\n",
    "            daily_ic.append(ic_by_day.assign(bagging_fraction=bagging_fraction,\n",
    "                                             feature_fraction=feature_fraction,\n",
    "                                             min_data_in_leaf=min_data_in_leaf))\n",
    "\n",
    "            cv_ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0]\n",
    "                  for n in num_iterations]\n",
    "\n",
    "            T += time() - start\n",
    "            ic.append([bagging_fraction, feature_fraction,\n",
    "                       min_data_in_leaf, lookahead] + cv_ic)\n",
    "\n",
    "            msg = f'{p:3.0f} | {format_time(T)} | '\n",
    "            msg += f'{bagging_fraction:3.0%} | {feature_fraction:3.0%} | {min_data_in_leaf:5,.0f} | '\n",
    "            msg += f'{max(cv_ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {ic_by_day.median().max(): 6.2%}'\n",
    "            print(msg)\n",
    "\n",
    "        m = pd.DataFrame(ic, columns=ic_cols)\n",
    "        m.to_hdf(cv_store, 'ic/' + key)\n",
    "        pd.concat(daily_ic).to_hdf(cv_store, 'daily_ic/' + key)\n",
    "        pd.concat(feature_importance).to_hdf(cv_store, 'fi/' + key)\n",
    "        pd.concat(predictions).to_hdf(cv_store, 'predictions/' + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Cross-Validation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now combine the CV results that we stored separately for each fold (to avoid loosing results in case something goes wrong along the way):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:08:11.601163Z",
     "start_time": "2021-02-23T21:08:11.598884Z"
    }
   },
   "outputs": [],
   "source": [
    "id_vars = ['train_length',\n",
    "           'test_length',\n",
    "           'bagging_fraction',\n",
    "           'feature_fraction',\n",
    "           'min_data_in_leaf',\n",
    "           't', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the financial performance in the notebook `alphalens_signal_quality`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:09:53.526684Z",
     "start_time": "2021-02-23T21:09:52.554548Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daily_ic, ic = [], []\n",
    "for t in lookaheads:\n",
    "    print(t)\n",
    "    with pd.HDFStore(cv_store) as store:\n",
    "        keys = [k[1:] for k in store.keys() if k.startswith(f'/fi/{t}')]\n",
    "        for key in keys:\n",
    "            train_length, test_length = key.split('/')[2:]\n",
    "            print(train_length, test_length)\n",
    "            k = f'{t}/{train_length}/{test_length}'\n",
    "            cols = {'t': t,\n",
    "                    'train_length': int(train_length),\n",
    "                    'test_length': int(test_length)}\n",
    "\n",
    "            ic.append(pd.melt(store['ic/' + k]\n",
    "                              .assign(**cols),\n",
    "                              id_vars=id_vars[:-1],\n",
    "                              value_name='ic',\n",
    "                              var_name='rounds')\n",
    "                      .apply(pd.to_numeric))\n",
    "\n",
    "            df = store['daily_ic/' + k].assign(**cols).reset_index()\n",
    "            daily_ic.append(pd.melt(df,\n",
    "                                    id_vars=id_vars,\n",
    "                                    value_name='daily_ic',\n",
    "                                    var_name='rounds')\n",
    "                            .set_index('date')\n",
    "                            .apply(pd.to_numeric)\n",
    "                            .reset_index())            \n",
    "ic = pd.concat(ic, ignore_index=True)\n",
    "daily_ic = pd.concat(daily_ic, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Performance: CV Information Coefficient by Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first look at the daily IC, the metric we ultimately care about for a daily trading strategy. The best results for all prediction horizons are typically achieved with three years of training; the shorter horizons work better with 21 day testing period length. More regularization often improves the result but the impact of the bagging and feature fraction parameters are a little less clear cut and likely depend on other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:09:56.260286Z",
     "start_time": "2021-02-23T21:09:56.033651Z"
    }
   },
   "outputs": [],
   "source": [
    "group_cols = ['t','train_length', 'test_length', \n",
    "              'bagging_fraction', 'feature_fraction', 'min_data_in_leaf']\n",
    "daily_ic_avg = daily_ic.groupby(group_cols + ['rounds']).daily_ic.mean().to_frame('ic').reset_index()\n",
    "daily_ic_avg.groupby('t', group_keys=False).apply(lambda x: x.nlargest(3, 'ic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:09:57.084490Z",
     "start_time": "2021-02-23T21:09:57.076867Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_ic_avg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a 1-day forecast horizon, over 75% of the predictions yield a positive daily IC; the same is true for 21 days which, unsurprisingly, also shows a wider range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:09:59.239313Z",
     "start_time": "2021-02-23T21:09:59.116945Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.boxenplot(x='t', y='ic', data=daily_ic_avg)\n",
    "ax.axhline(0, ls='--', lw=1, c='k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:00.267110Z",
     "start_time": "2021-02-23T21:09:59.282710Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.catplot(x='t',\n",
    "                y='ic',\n",
    "                col='train_length',\n",
    "                row='test_length',\n",
    "                data=daily_ic_avg[(daily_ic_avg.test_length == 21)],\n",
    "                kind='boxen')\n",
    "g.savefig(results_path / 'daily_ic_test_21', dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Impact: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better idea of how the various CV parameters impact the forecast quality, we can run a linear regression with the daily IC as outcome and the one-hot encoded hyperparameters as inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:03.122098Z",
     "start_time": "2021-02-23T21:10:03.056750Z"
    }
   },
   "outputs": [],
   "source": [
    "lin_reg = {}\n",
    "for t in [1, 5]:\n",
    "    df_ = daily_ic_avg[(daily_ic_avg.t==t)&(daily_ic_avg.rounds<=250)].dropna()\n",
    "    y, X = df_.ic, df_.drop(['ic', 't'], axis=1)\n",
    "    X = sm.add_constant(pd.get_dummies(X, columns=X.columns, drop_first=True))\n",
    "    X = X.astype(int)\n",
    "    model = sm.OLS(endog=y, exog=X)\n",
    "    lin_reg[t] = model.fit()\n",
    "    s = lin_reg[t].summary()\n",
    "    coefs = pd.read_csv(StringIO(s.tables[1].as_csv())).rename(\n",
    "        columns=lambda x: x.strip())\n",
    "    coefs.columns = ['variable', 'coef', 'std_err',\n",
    "                     't', 'p_value', 'ci_low', 'ci_high']\n",
    "    coefs.to_csv(results_path / f'lr_result_{t:02}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:03.695084Z",
     "start_time": "2021-02-23T21:10:03.686275Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_lr_result(model, ax):\n",
    "    ci = model.conf_int()\n",
    "    errors = ci[1].sub(ci[0]).div(2)\n",
    "\n",
    "    coefs = (model.params.to_frame('coef').assign(error=errors)\n",
    "             .reset_index().rename(columns={'index': 'variable'}))\n",
    "    coefs = coefs[~coefs['variable'].str.startswith(\n",
    "        'date') & (coefs.variable != 'const')]\n",
    "    coefs.variable = coefs.variable.str.split('_').str[-1]\n",
    "\n",
    "    coefs.plot(x='variable', y='coef', kind='bar', ax=ax, \n",
    "               color='none', capsize=3, yerr='error', legend=False, rot=0)    \n",
    "    ax.set_ylabel('IC')\n",
    "    ax.set_xlabel('')\n",
    "    ax.scatter(x=pd.np.arange(len(coefs)), marker='_', s=120, y=coefs['coef'], color='black')\n",
    "    ax.axhline(y=0, linestyle='--', color='black', linewidth=1)\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "\n",
    "    ax.annotate('Train\\nLength', xy=(.09, -0.1), xytext=(.09, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=5, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "    ax.annotate('Test\\nLength', xy=(.23, -0.1), xytext=(.23, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=2, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "    ax.annotate('Bagging\\nFraction', xy=(.32, -0.1), xytext=(.32, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=2.7, lengthB=0.8', lw=1.0, color='black'))\n",
    "\n",
    "\n",
    "    ax.annotate('Feature\\nFraction', xy=(.44, -0.1), xytext=(.44, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=3.4, lengthB=1.0', lw=1.0, color='black'))\n",
    "    \n",
    "\n",
    "    ax.annotate('Min.\\nSamples', xy=(.55, -0.1), xytext=(.55, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=2.5, lengthB=1.0', lw=1.0, color='black'))    \n",
    "    \n",
    "    ax.annotate('Number of\\nRounds', xy=(.8, -0.1), xytext=(.8, -0.2),\n",
    "                xycoords='axes fraction',\n",
    "                textcoords='axes fraction',\n",
    "                fontsize=11, ha='center', va='bottom',\n",
    "                bbox=dict(boxstyle='square', fc='white', ec='black'),\n",
    "                arrowprops=dict(arrowstyle='-[, widthB=11.2, lengthB=1.0', lw=1.0, color='black'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below plot shows the regression coefficient values and their confidence intervals. The intercept (not shown) has a small positive value and is statistically signifant; it captures the impact of the dropped categories (the smallest value for each parameter).\n",
    "\n",
    "For 1-day forecasts, some but not all results are insightful: 21-day testing is better, and so is `min_samples_leaf` of 500 or 1,000. 100-200 trees seem to work best, but both shorter and longer training periods are better than intermediate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:06.305149Z",
     "start_time": "2021-02-23T21:10:05.696990Z"
    }
   },
   "outputs": [],
   "source": [
    "#with sns.axes_style('white'):\n",
    "#    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\n",
    "#    axes = axes.flatten()\n",
    "#    for i, t in enumerate([1, 5]):\n",
    "#        visualize_lr_result(lin_reg[t], axes[i])\n",
    "#        axes[i].set_title(f'Lookahead: {t} Day(s)')\n",
    "#    fig.suptitle('OLS Coefficients & Confidence Intervals', fontsize=20)\n",
    "#    fig.tight_layout()\n",
    "#    fig.subplots_adjust(top=.92)\n",
    "\n",
    "def visualize_lr_result(results, ax):\n",
    "    # Sample implementation, replace with your actual function details\n",
    "    summary_df = results.summary2().tables[1]\n",
    "    summary_df.reset_index(inplace=True)\n",
    "    summary_df.columns = ['Variable', 'Coef', 'Std Err', 't', 'P>|t|', '[0.025', '0.975]']\n",
    "    summary_df.plot(kind='bar', x='Variable', y='Coef', yerr=[summary_df['Coef'] - summary_df['[0.025'], summary_df['0.975]'] - summary_df['Coef']], ax=ax, capsize=4)\n",
    "    ax.set_ylabel('Coefficient')\n",
    "    ax.set_xlabel('Variables')\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\n",
    "    axes = axes.flatten()\n",
    "    for i, t in enumerate([1, 5]):\n",
    "        visualize_lr_result(lin_reg[t], axes[i])\n",
    "        axes[i].set_title(f'Lookahead: {t} Day(s)')\n",
    "    fig.suptitle('OLS Coefficients & Confidence Intervals', fontsize=20)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=.92)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Coefficient: Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also take a look at the overall IC value, which is often reported but does not necessarily match the goal of a daily trading strategy that uses the model return predictions as well as the daily IC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:24.159865Z",
     "start_time": "2021-02-23T21:10:24.148886Z"
    }
   },
   "outputs": [],
   "source": [
    "ic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directionally, and for shorter periods, similar hyperparameter settings work best (while the IC values are higher):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:26.999923Z",
     "start_time": "2021-02-23T21:10:26.983402Z"
    }
   },
   "outputs": [],
   "source": [
    "ic.groupby('t').apply(lambda x: x.nlargest(3, 'ic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualiztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:28.369762Z",
     "start_time": "2021-02-23T21:10:27.970520Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.catplot(x='t',\n",
    "                y='ic',\n",
    "                col='train_length',\n",
    "                row='test_length',\n",
    "                data=ic[(ic.test_length == 21) & (ic.t < 21)],\n",
    "                kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:37.904492Z",
     "start_time": "2021-02-23T21:10:30.194796Z"
    }
   },
   "outputs": [],
   "source": [
    "t = 1\n",
    "train_length = 756\n",
    "test_length = 21\n",
    "g = sns.catplot(x='rounds',\n",
    "    y='ic',\n",
    "    col='feature_fraction',\n",
    "    hue='bagging_fraction',\n",
    "    row='min_data_in_leaf',\n",
    "    data=ic[(ic.t == t) &\n",
    "            (ic.train_length == train_length) &\n",
    "            (ic.test_length == test_length)],\n",
    "    kind='swarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest vs Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the best-performing (in-sample) random forest models to our linear regression baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:51.280229Z",
     "start_time": "2021-02-23T21:10:51.271304Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_metrics = pd.read_csv(results_path / 'lin_reg_performance.csv')\n",
    "lr_metrics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:52.660412Z",
     "start_time": "2021-02-23T21:10:52.652725Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_ic_avg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are mixed: for the shortest and longest horizons, the random forest outperforms (slightly for 1 day), while linear regression is competitive for the intermediate horizons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:55.223622Z",
     "start_time": "2021-02-23T21:10:55.032734Z"
    }
   },
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "    ax = (ic.groupby('t').ic.max().to_frame('Random Forest')\n",
    "     .join(lr_metrics.groupby('lookahead').ic.max().to_frame('Linear Regression')).plot.barh())\n",
    "    ax.set_ylabel('Lookahead')\n",
    "    ax.set_xlabel('Information Coefficient')\n",
    "    sns.despine()\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build and evaluate a trading strategy, we create predictions for the 2018-19 period using the 10 best models that we then ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:56.276550Z",
     "start_time": "2021-02-23T21:10:56.274762Z"
    }
   },
   "outputs": [],
   "source": [
    "param_cols = ['train_length', 'test_length', 'bagging_fraction',\n",
    "              'feature_fraction', 'min_data_in_leaf', 'rounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:58.310089Z",
     "start_time": "2021-02-23T21:10:58.304594Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_params(data, t=5, best=0):\n",
    "    df = data[data.t == t].sort_values('ic', ascending=False).iloc[best]\n",
    "    df = df.loc[param_cols]\n",
    "    rounds = int(df.rounds)\n",
    "    params = pd.to_numeric(df.drop('rounds'))\n",
    "    return params, rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:10:58.550817Z",
     "start_time": "2021-02-23T21:10:58.548693Z"
    }
   },
   "outputs": [],
   "source": [
    "base_params = dict(boosting_type='rf',\n",
    "                   objective='regression',\n",
    "                   bagging_freq=1,\n",
    "                   verbose=-1)\n",
    "\n",
    "store = Path(results_path / 'predictions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T21:39:01.014230Z",
     "start_time": "2021-02-23T21:29:25.042746Z"
    }
   },
   "outputs": [],
   "source": [
    "for lookahead in [1, 5, 10, 21]:\n",
    "    if lookahead > 1: \n",
    "        continue\n",
    "    print(f'\\nLookahead: {lookahead:02}')\n",
    "    data = (pd.read_hdf('data.h5', 'stooq/japan/equities'))\n",
    "    labels = sorted(data.filter(like='fwd').columns)\n",
    "    features = data.columns.difference(labels).tolist()\n",
    "    label = f'fwd_ret_{lookahead:02}'\n",
    "    data = data.loc[:, features + [label]].dropna()\n",
    "\n",
    "    categoricals = ['year', 'weekday', 'month']\n",
    "    for feature in categoricals:\n",
    "        data[feature] = pd.factorize(data[feature], sort=True)[0]\n",
    "\n",
    "    lgb_data = lgb.Dataset(data=data[features],\n",
    "                           label=data[label],\n",
    "                           categorical_feature=categoricals,\n",
    "                           free_raw_data=False)\n",
    "    \n",
    "    for position in range(10):\n",
    "        params, num_boost_round = get_params(daily_ic_avg,\n",
    "                                             t=lookahead,\n",
    "                                             best=position)\n",
    "        params = params.to_dict()\n",
    "        params['min_data_in_leaf'] = int(params['min_data_in_leaf'])\n",
    "        train_length = int(params.pop('train_length'))\n",
    "        test_length = int(params.pop('test_length'))\n",
    "        params.update(base_params)\n",
    "\n",
    "        print(f'\\tPosition: {position:02}')\n",
    "\n",
    "        n_splits = int(2 * YEAR / test_length)\n",
    "        cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                                  test_period_length=test_length,\n",
    "                                  lookahead=lookahead,\n",
    "                                  train_period_length=train_length)\n",
    "\n",
    "        predictions = []\n",
    "        start = time()\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=data), 1):\n",
    "            train_set = lgb_data.subset(used_indices=train_idx.tolist(),\n",
    "                                        params=params).construct()\n",
    "    \n",
    "            model = lgb.train(params=params,\n",
    "                              train_set=train_set,\n",
    "                              num_boost_round=num_boost_round)\n",
    "\n",
    "            test_set = data.iloc[test_idx, :]\n",
    "            y_test = test_set.loc[:, label].to_frame('y_test')\n",
    "            y_pred = model.predict(test_set.loc[:, model.feature_name()])\n",
    "            predictions.append(y_test.assign(prediction=y_pred))\n",
    "\n",
    "        if position == 0:\n",
    "            test_predictions = (pd.concat(predictions)\n",
    "                                .rename(columns={'prediction': position}))\n",
    "        else:\n",
    "            test_predictions[position] = pd.concat(predictions).prediction\n",
    "        \n",
    "\n",
    "    by_day = test_predictions.groupby(level='date')\n",
    "    for position in range(10):\n",
    "        if position == 0:\n",
    "            ic_by_day = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0]).to_frame()\n",
    "        else:\n",
    "            ic_by_day[position] = by_day.apply(lambda x: spearmanr(x.y_test, x[position])[0])\n",
    "\n",
    "    test_predictions.to_hdf(store, f'test/{lookahead:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "file_path = 'results/return_predictions/parameter_tuning.h5'\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # Print all the top-level keys (datasets or groups)\n",
    "    def print_keys(name, obj):\n",
    "        print(name)\n",
    "    \n",
    "    # Traverse the HDF5 file structure\n",
    "    file.visititems(print_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.162px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
