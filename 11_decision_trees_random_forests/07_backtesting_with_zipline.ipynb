{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting with Zipline - Using the Pipeline API with ML-driven Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:48.871334Z",
     "start_time": "2021-04-16T00:44:48.869600Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:50.080929Z",
     "start_time": "2021-04-16T00:44:48.876220Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader.data as web\n",
    "from logbook import Logger, StderrHandler, INFO\n",
    "\n",
    "from zipline import run_algorithm\n",
    "from zipline.api import (attach_pipeline, pipeline_output,\n",
    "                         date_rules, time_rules, record,\n",
    "                         schedule_function, commission, slippage,\n",
    "                         set_slippage, set_commission,\n",
    "                         get_open_orders, cancel_order,\n",
    "                         order_target, order_target_percent)\n",
    "from zipline.data import bundles\n",
    "from zipline.utils.run_algo import load_extensions\n",
    "from zipline.pipeline import Pipeline, CustomFactor\n",
    "from zipline.pipeline.data import Column, DataSet\n",
    "from zipline.pipeline.domain import JP_EQUITIES\n",
    "from zipline.pipeline.filters import StaticAssets\n",
    "from zipline.pipeline.loaders.frame import DataFrameLoader\n",
    "\n",
    "import pyfolio as pf\n",
    "from pyfolio.plotting import plot_rolling_returns, plot_rolling_sharpe\n",
    "from pyfolio.timeseries import forecast_cone_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:50.083865Z",
     "start_time": "2021-04-16T00:44:50.081951Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:50.098371Z",
     "start_time": "2021-04-16T00:44:50.085117Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('results', 'return_predictions')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load zipline extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only need this in notebook to find bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:50.106730Z",
     "start_time": "2021-04-16T00:44:50.099390Z"
    }
   },
   "outputs": [],
   "source": [
    "load_extensions(default=True,\n",
    "                extensions=[],\n",
    "                strict=True,\n",
    "                environ=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:50.113800Z",
     "start_time": "2021-04-16T00:44:50.107601Z"
    }
   },
   "outputs": [],
   "source": [
    "log_handler = StderrHandler(format_string='[{record.time:%Y-%m-%d %H:%M:%S.%f}]: ' +\n",
    "                            '{record.level_name}: {record.func_name}: {record.message}',\n",
    "                            level=INFO)\n",
    "log_handler.push_application()\n",
    "log = Logger('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy will hold the 25 stocks with the highest positive and lowest negative predictions each as long as there are at least 15 on each side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:50.124701Z",
     "start_time": "2021-04-16T00:44:50.114658Z"
    }
   },
   "outputs": [],
   "source": [
    "N_LONGS = 25\n",
    "N_SHORTS = 25\n",
    "MIN_POSITIONS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quandl Wiki Bundel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:50.348572Z",
     "start_time": "2021-04-16T00:44:50.125519Z"
    }
   },
   "outputs": [],
   "source": [
    "bundle_data = bundles.load('stooq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the `train` predictions in the notebook `alphalens_signal_quality` and the `test` predictions in the notebook `random_forest_return_signals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:50.353055Z",
     "start_time": "2021-04-16T00:44:50.350015Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_predictions(bundle):\n",
    "    t = 1\n",
    "    #df = pd.concat([pd.read_hdf(results_path / 'predictions.h5', 'train/{:02}'.format(t)),\n",
    "    #                pd.read_hdf(results_path / 'predictions.h5', 'test/{:02}'.format(t))])\n",
    "    df = pd.concat([pd.read_hdf(results_path / 'predictions.h5', 'test/{:02}'.format(t))])\n",
    "    df = df[~df.index.duplicated()].drop('y_test', axis=1)\n",
    "    predictions = df.iloc[:, :5].mean(1).to_frame('predictions')\n",
    "\n",
    "    tickers = predictions.index.get_level_values('ticker').unique().tolist()\n",
    "\n",
    "    assets = bundle.asset_finder.lookup_symbols(tickers, as_of_date=None)\n",
    "    predicted_sids = pd.Index([asset.sid for asset in assets])\n",
    "    ticker_map = dict(zip(tickers, predicted_sids))\n",
    "\n",
    "    return (predictions\n",
    "            .unstack('ticker')\n",
    "            .rename(columns=ticker_map)\n",
    "            .predictions\n",
    "            #.tz_localize('UTC')), \n",
    "            .tz_localize(None)),\n",
    "            assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.148200Z",
     "start_time": "2021-04-16T00:44:50.354197Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions, assets = load_predictions(bundle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.176690Z",
     "start_time": "2021-04-16T00:44:52.149053Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.191192Z",
     "start_time": "2021-04-16T00:44:52.177551Z"
    }
   },
   "outputs": [],
   "source": [
    "class SignalData(DataSet):\n",
    "    predictions = Column(dtype=float)\n",
    "    domain = JP_EQUITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.201374Z",
     "start_time": "2021-04-16T00:44:52.192011Z"
    }
   },
   "outputs": [],
   "source": [
    "signal_loader = {SignalData.predictions:\n",
    "                 DataFrameLoader(SignalData.predictions, predictions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom ML Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.207598Z",
     "start_time": "2021-04-16T00:44:52.202405Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLSignal(CustomFactor):\n",
    "    \"\"\"Converting signals to Factor\n",
    "        so we can rank and filter in Pipeline\"\"\"\n",
    "    inputs = [SignalData.predictions]\n",
    "    window_length = 1\n",
    "\n",
    "    def compute(self, today, assets, out, preds):\n",
    "        out[:] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.217674Z",
     "start_time": "2021-04-16T00:44:52.208668Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_signals():\n",
    "    signals = MLSignal()\n",
    "    predictions = SignalData.predictions.latest\n",
    "    return Pipeline(columns={\n",
    "        'longs': signals.top(N_LONGS, mask=signals > 0),\n",
    "        'shorts': signals.bottom(N_SHORTS, mask=signals < 0)},\n",
    "        screen=StaticAssets(assets)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.227061Z",
     "start_time": "2021-04-16T00:44:52.220443Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize(context):\n",
    "    \"\"\"\n",
    "    Called once at the start of the algorithm.\n",
    "    \"\"\"\n",
    "    context.n_longs = N_LONGS\n",
    "    context.n_shorts = N_SHORTS\n",
    "    context.min_positions = MIN_POSITIONS\n",
    "    context.universe = assets\n",
    "    context.trades = pd.Series()\n",
    "\n",
    "    set_slippage(slippage.FixedSlippage(spread=0.00))\n",
    "    set_commission(commission.PerShare(cost=0.05, min_trade_cost=1))\n",
    "\n",
    "    schedule_function(rebalance,\n",
    "                      date_rules.every_day(),\n",
    "                      time_rules.market_open(hours=1, minutes=30))\n",
    "\n",
    "    schedule_function(record_vars,\n",
    "                      date_rules.every_day(),\n",
    "                      time_rules.market_close())\n",
    "\n",
    "    pipeline = compute_signals()\n",
    "    attach_pipeline(pipeline, 'signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get daily Pipeline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.239790Z",
     "start_time": "2021-04-16T00:44:52.229017Z"
    }
   },
   "outputs": [],
   "source": [
    "def before_trading_start(context, data):\n",
    "    \"\"\"\n",
    "    Called every day before market open.\n",
    "    \"\"\"\n",
    "    output = pipeline_output('signals')\n",
    "    #context.trades = (output['longs'].astype(int)\n",
    "    #                  .append(output['shorts'].astype(int).mul(-1))\n",
    "    #                  .reset_index()\n",
    "    #                  .drop_duplicates()\n",
    "    #                  .set_index('index')\n",
    "    #                  .squeeze())\n",
    "\n",
    "    longs = output['longs'].astype(int)\n",
    "    shorts = output['shorts'].astype(int).mul(-1)\n",
    "\n",
    "    # Using pd.concat instead of append\n",
    "    combined = pd.concat([longs, shorts], axis=0).reset_index().drop_duplicates().set_index('index').squeeze()\n",
    "    \n",
    "    context.trades = combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Rebalancing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.251991Z",
     "start_time": "2021-04-16T00:44:52.242449Z"
    }
   },
   "outputs": [],
   "source": [
    "def rebalance(context, data):\n",
    "    \"\"\"\n",
    "    Execute orders according to schedule_function() date & time rules.\n",
    "    \"\"\"\n",
    "    trades = defaultdict(list)\n",
    "    for symbol, open_orders in get_open_orders().items():\n",
    "        for open_order in open_orders:\n",
    "            cancel_order(open_order)\n",
    "\n",
    "    positions = context.portfolio.positions\n",
    "    s = (pd.Series({s: v.amount*v.last_sale_price for s,\n",
    "                    v in positions.items()})\n",
    "         .sort_values(ascending=False))\n",
    "    \n",
    "    for stock, trade in context.trades.items():\n",
    "        if trade == 0:\n",
    "            order_target(stock, target=0)\n",
    "        else:\n",
    "            trades[trade].append(stock)\n",
    "\n",
    "    context.longs, context.shorts = len(trades[1]), len(trades[-1])\n",
    "    if context.longs > context.min_positions and context.shorts > context.min_positions:\n",
    "        for stock in trades[-1]:\n",
    "            order_target_percent(stock, -1 / context.shorts)\n",
    "        for stock in trades[1]:\n",
    "            order_target_percent(stock, 1 / context.longs)\n",
    "    else:\n",
    "        for stock in trades[-1] + trades[1]:\n",
    "            if stock in positions:\n",
    "                order_target(stock, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.263892Z",
     "start_time": "2021-04-16T00:44:52.253869Z"
    }
   },
   "outputs": [],
   "source": [
    "def record_vars(context, data):\n",
    "    \"\"\"\n",
    "    Plot variables at the end of each day.\n",
    "    \"\"\"\n",
    "    record(leverage=context.account.leverage,\n",
    "           longs=context.longs,\n",
    "           shorts=context.shorts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.272645Z",
     "start_time": "2021-04-16T00:44:52.266129Z"
    }
   },
   "outputs": [],
   "source": [
    "dates = predictions.index.get_level_values('date')\n",
    "#start_date = dates.min() + pd.DateOffset(day=1)\n",
    "#end_date = dates.max()\n",
    "\n",
    "start_date = dates.min().tz_localize(None) + pd.DateOffset(day=1)\n",
    "end_date = dates.max().tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:44:52.286014Z",
     "start_time": "2021-04-16T00:44:52.274955Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Start:\\t{}\\nEnd:\\t{}'.format(start_date.date(), end_date.date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:45:11.968963Z",
     "start_time": "2021-04-16T00:44:52.287048Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "results = run_algorithm(start=start_date,\n",
    "                        end=end_date,\n",
    "                        initialize=initialize,\n",
    "                        before_trading_start=before_trading_start,\n",
    "                        capital_base=1e6,\n",
    "                        data_frequency='daily',\n",
    "                        bundle='stooq',\n",
    "                        custom_loader=signal_loader)# need to modify zipline\n",
    "\n",
    "print('Duration: {:.2f}s'.format(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyFolio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:45:12.600883Z",
     "start_time": "2021-04-16T00:45:11.969974Z"
    }
   },
   "outputs": [],
   "source": [
    "returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:52:59.026817Z",
     "start_time": "2021-04-16T00:52:55.485132Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = web.DataReader('NIKKEI225', \n",
    "                           'fred', \n",
    "                           start='2015', \n",
    "                           end='2020').squeeze()\n",
    "benchmark = benchmark.pct_change().tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:45:14.058695Z",
     "start_time": "2021-04-16T00:45:13.062618Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(16, 5))\n",
    "plot_rolling_returns(returns,\n",
    "                     factor_returns=benchmark,\n",
    "                     live_start_date='2018-01-01',\n",
    "                     logy=False,\n",
    "                     cone_std=2,\n",
    "                     legend_loc='best',\n",
    "                     volatility_match=False,\n",
    "                     cone_function=forecast_cone_bootstrap,\n",
    "                    ax=axes[0])\n",
    "plot_rolling_sharpe(returns, ax=axes[1], rolling_window=63)\n",
    "axes[0].set_title('Cumulative Returns - In and Out-of-Sample')\n",
    "axes[1].set_title('Rolling Sharpe Ratio (3 Months)')\n",
    "fig.tight_layout()\n",
    "fig.savefig((results_path / 'pyfolio_out_of_sample').as_posix(), dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tear Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:45:39.408548Z",
     "start_time": "2021-04-16T00:45:14.059725Z"
    }
   },
   "outputs": [],
   "source": [
    "pf.create_full_tear_sheet(returns, \n",
    "                          positions=positions, \n",
    "                          transactions=transactions,\n",
    "                          benchmark_rets=benchmark,\n",
    "                          live_start_date='2018-01-01', \n",
    "                          round_trips=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
